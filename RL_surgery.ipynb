{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9407ca8-e037-42a9-83d7-284d664dfce1",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed4ac3c-960e-4b42-88ee-a8832f6de282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "from statistics import mean\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, PReLU, Conv2D, Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import random as rnd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95f73ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "keras               2.8.0\n",
       "matplotlib          3.5.1\n",
       "numpy               1.21.5\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                                         9.0.1\n",
       "aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42    NA\n",
       "absl                                        NA\n",
       "astunparse                                  1.6.3\n",
       "backcall                                    0.2.0\n",
       "certifi                                     2021.10.08\n",
       "cffi                                        1.15.0\n",
       "charset_normalizer                          2.0.12\n",
       "colorama                                    0.4.4\n",
       "cycler                                      0.10.0\n",
       "cython_runtime                              NA\n",
       "dateutil                                    2.8.2\n",
       "debugpy                                     1.5.1\n",
       "decorator                                   5.1.0\n",
       "defusedxml                                  0.7.1\n",
       "entrypoints                                 0.3\n",
       "flatbuffers                                 2.0\n",
       "gast                                        0.5.3\n",
       "google                                      NA\n",
       "h5py                                        3.6.0\n",
       "idna                                        3.3\n",
       "ipykernel                                   6.6.0\n",
       "ipython_genutils                            0.2.0\n",
       "jedi                                        0.18.1\n",
       "keras_preprocessing                         1.1.2\n",
       "kiwisolver                                  1.4.2\n",
       "matplotlib_inline                           NA\n",
       "mpl_toolkits                                NA\n",
       "ntsecuritycon                               NA\n",
       "opt_einsum                                  v3.3.0\n",
       "packaging                                   21.3\n",
       "pandas                                      1.3.5\n",
       "parso                                       0.8.3\n",
       "pickleshare                                 0.7.5\n",
       "pkg_resources                               NA\n",
       "prompt_toolkit                              3.0.24\n",
       "pydev_ipython                               NA\n",
       "pydevconsole                                NA\n",
       "pydevd                                      2.6.0\n",
       "pydevd_concurrency_analyser                 NA\n",
       "pydevd_file_utils                           NA\n",
       "pydevd_plugins                              NA\n",
       "pydevd_tracing                              NA\n",
       "pygments                                    2.11.0\n",
       "pyparsing                                   3.0.6\n",
       "pythoncom                                   NA\n",
       "pytz                                        2021.3\n",
       "pywin32_bootstrap                           NA\n",
       "pywin32_system32                            NA\n",
       "pywintypes                                  NA\n",
       "requests                                    2.27.1\n",
       "scipy                                       1.8.0\n",
       "six                                         1.16.0\n",
       "storemagic                                  NA\n",
       "tensorboard                                 2.8.0\n",
       "tensorflow                                  2.8.0\n",
       "termcolor                                   1.1.0\n",
       "tornado                                     6.1\n",
       "traitlets                                   5.1.1\n",
       "typing_extensions                           NA\n",
       "urllib3                                     1.26.9\n",
       "wcwidth                                     0.2.5\n",
       "win32api                                    NA\n",
       "win32com                                    NA\n",
       "win32security                               NA\n",
       "wrapt                                       1.14.0\n",
       "zmq                                         22.3.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             7.30.1\n",
       "jupyter_client      7.1.0\n",
       "jupyter_core        4.9.1\n",
       "notebook            6.4.6\n",
       "-----\n",
       "Python 3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]\n",
       "Windows-10-10.0.22621-SP0\n",
       "-----\n",
       "Session information updated at 2023-07-04 17:05\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99121169-9721-45ba-be1f-4c67b8e8c59c",
   "metadata": {},
   "source": [
    "## Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e3da7a-da4f-47c9-8b7e-a0e5467de898",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here you can find all the classes and the custom functions used for this project'''\n",
    "\n",
    "class SurgeryEnv: \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.size = 10 #size of the grid \n",
    "        self.surgery_mat =  -np.ones((self.size+1, self.size+1), dtype=np.int32) #the matrix that represents the environment\n",
    "        self.knife_position_x = 3 #position of the knife (x coordinate)\n",
    "        self.knife_position_y = 5 #position of the knife (y coordinate)\n",
    "        self.original_knife_coordinates = (3,5)\n",
    "        self.object_points = [(4,4), (4,5),(4,6),(5,4),(5,5),(5,6),(6,4),(6,5),(6,6)] #points of the matrix that correspond to the object to be removed (in this case the uterus)\n",
    "        self.object_value = 32  #the value that identify the uterus in the matrix\n",
    "        self.target_points = [(3,4), (3,6), (4,7),(4,8),(5,8),(4,3),(4,2),(5,2),(7,4), (8,4), (7,6), (8,6)] #points of the matrix that correspond to the target area (the objective of the Agent is to cut these points)\n",
    "        self.target_value = 64 #the value that identify the target area in the matrix\n",
    "        self.ligart_points = [(1,4), (2,4), (1,6),(2,6),(5,3),(4,1),(5,1),(5,7),(4,9), (5,9), (9,4), (9,6)] #points of the matrix that correspond to the area of ligaments and/or arteries (these must be avoided)\n",
    "        self.ligart_value = 128 #the value that identify ligaments and arteries in the matrix\n",
    "        self.peritoneum_value = 255 #the value that identify the peritoneum (the points in which the Agent can navigate) in the matrix\n",
    "        self.knife_value = 16 #the value assigned to the knife\n",
    "        self.path = [] #list to take trace of the path of the knife\n",
    "        self.taken_actions = [] #list to take trace of the actions taken by the knife\n",
    "        self.action_space = [0,1,2,3] #possible actions\n",
    "        self.actions_dict = {0:'up', 1:'right', 2:'down', 3:'left'} #dictionary to associate to each value the correspondent action\n",
    "        self.n_actions = len(self.action_space) #number of possible actions\n",
    "        \n",
    "    def gen_env(self):\n",
    "\n",
    "        '''Creating the frame'''\n",
    "        self.surgery_mat[0] = 0 #first row\n",
    "        self.surgery_mat[-1] = 0 #last row\n",
    "        self.surgery_mat[:, -1] = 0 # last column\n",
    "        self.surgery_mat[:, 0] = 0 #first column\n",
    "\n",
    "        '''Creating the object at the center'''\n",
    "        for object_point in self.object_points:\n",
    "            self.surgery_mat[object_point[0], object_point[1]] = self.object_value\n",
    "\n",
    "        '''Creating the target area'''\n",
    "        for target_point in self.target_points:\n",
    "            self.surgery_mat[target_point[0], target_point[1]] = self.target_value\n",
    "\n",
    "        '''Creating ligaments and arteries'''\n",
    "        for ligart_point in self.ligart_points:\n",
    "            self.surgery_mat[ligart_point[0], ligart_point[1]] = self.ligart_value\n",
    "\n",
    "        '''Creating peritoneum'''\n",
    "        mask = self.surgery_mat == -1\n",
    "        self.surgery_mat[mask] = self.peritoneum_value\n",
    "\n",
    "        return self.surgery_mat.copy()\n",
    "\n",
    "    def plot_env(self):\n",
    "\n",
    "        '''Plot'''\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.imshow(self.surgery_mat)\n",
    "        plt.show()\n",
    "        \n",
    "    def step_env(self, action):\n",
    "        \n",
    "        reward = 0\n",
    "        done = False\n",
    "        \n",
    "        self.path.append((self.knife_position_x, self.knife_position_y)) #take trace of the position of the knife\n",
    "        \n",
    "        '''Applying action'''\n",
    "        if action == 0: #up\n",
    "            self.knife_position_x = self.knife_position_x-1\n",
    "            \n",
    "        if action == 1: #right\n",
    "            self.knife_position_y = self.knife_position_y+1\n",
    "            \n",
    "        if action == 2: #down\n",
    "            self.knife_position_x = self.knife_position_x+1\n",
    "            \n",
    "        if action == 3: #left\n",
    "            self.knife_position_y = self.knife_position_y-1\n",
    "        \n",
    "        '''Determine reward and done values'''\n",
    "        if self.surgery_mat[self.knife_position_x,self.knife_position_y] == 0: #frame\n",
    "            reward = -5\n",
    "            done=True\n",
    "            \n",
    "        if self.surgery_mat[self.knife_position_x,self.knife_position_y] == self.object_value: #uterus\n",
    "            reward = -5\n",
    "            done=True\n",
    "            \n",
    "        if self.surgery_mat[self.knife_position_x,self.knife_position_y] == self.target_value: #target\n",
    "            reward = +5\n",
    "            \n",
    "        if self.surgery_mat[self.knife_position_x,self.knife_position_y] == self.ligart_value: #ligaments or arteries\n",
    "            reward = -3\n",
    "            \n",
    "        if self.surgery_mat[self.knife_position_x,self.knife_position_y] == self.peritoneum_value: #peritoneum\n",
    "            reward = -1\n",
    "            \n",
    "        if self.surgery_mat[self.knife_position_x,self.knife_position_y] == self.knife_value: #cells already visited\n",
    "            reward = -3\n",
    "            \n",
    "        self.surgery_mat[self.knife_position_x,self.knife_position_y] = self.knife_value #set the new position of the knife\n",
    "        \n",
    "        mask = self.surgery_mat == self.target_value #check that all the target area is gone\n",
    "        if not mask.any():\n",
    "            done=True\n",
    "    \n",
    "        self.taken_actions.append(self.actions_dict[action]) #take trace of the current action\n",
    "        \n",
    "                                                                            #info\n",
    "        return self.surgery_mat.copy(), reward, done, {'path': self.path, 'taken_actions': self.taken_actions} \n",
    "        \n",
    "    def reset_env(self):\n",
    "        \n",
    "        '''Generating the basic environment'''\n",
    "        self.surgery_mat = self.gen_env()\n",
    "        \n",
    "        ''' Cleaning the history of the knife'''\n",
    "        self.path = []\n",
    "        self.taken_actions = []\n",
    "       \n",
    "        '''Positioning the knife'''\n",
    "        self.knife_position_x = self.original_knife_coordinates[0]\n",
    "        self.knife_position_y = self.original_knife_coordinates[1]\n",
    "        self.surgery_mat[self.original_knife_coordinates[0], self.original_knife_coordinates[1]] = self.knife_value\n",
    "\n",
    "'''Replay function for training the Agent on past steps'''        \n",
    "def replay(model, replay_memory, minibatch_size, env_size, gamma = 0.7):\n",
    "\n",
    "    inputs = np.zeros((minibatch_size, env_size))\n",
    "    targets = np.zeros((minibatch_size, n_actions))\n",
    "    \n",
    "    minibatch = np.random.choice(replay_memory, minibatch_size, replace=True) \n",
    "    \n",
    "    '''Splitting states, actions, rewards etc. in lists'''\n",
    "    state_list = np.array(list(map(lambda x: x['s'], minibatch)))\n",
    "    action_list = np.array(list(map(lambda x: x['a'], minibatch)))\n",
    "    reward_list = np.array(list(map(lambda x: x['r'], minibatch)))\n",
    "    s_prime_list = np.array(list(map(lambda x: x['s_prime'], minibatch)))\n",
    "    done_list = np.array(list(map(lambda x: x['done'], minibatch)))\n",
    "    \n",
    "    '''Taking, for each step in the batch, the state where the Agent started, the action performed to reach the next state (s_prime), the reward and so on. \n",
    "    Use these values to compute the Q values.'''\n",
    "    for i, (s,a,r,sprime,done) in enumerate(zip(state_list, action_list, reward_list, s_prime_list, done_list)):\n",
    "        inputs[i] = s\n",
    "        targets[i] = model.predict(s)\n",
    "        Q_sa = np.max(model.predict(sprime))\n",
    "        if not done:\n",
    "            targets[i,a] = r + gamma * Q_sa\n",
    "        else:\n",
    "            targets[i,a] = r \n",
    "    \n",
    "    model.fit(inputs, targets, epochs=10, verbose=0) #training the model\n",
    "    \n",
    "    return model\n",
    "\n",
    "'''Function for creating the animation of the Agent in the Environment'''\n",
    "def animate_func(i):\n",
    "    \n",
    "    im.set_array(frames[i])\n",
    "    return [im]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8918d610-0e67-4612-ad50-334da8f759a9",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90133e2d-4ea3-4028-a9fb-ce98d5a13c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "surgery_env = SurgeryEnv()\n",
    "surgery_env.gen_env() \n",
    "surgery_env.plot_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abdd9e7-e79c-4814-af7c-01c04d288ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = surgery_env.n_actions\n",
    "input_shape = surgery_env.surgery_mat.reshape(-1, surgery_env.size+1, 1).shape #for the model definition\n",
    "print('Input shape:', input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b5f52-bc3b-4842-8261-8382a08cf91f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f76ba99-a4a3-4133-8ec8-e9a2dae06d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This is the model used in the original paper'''\n",
    "model = Sequential(name=\"sequential_layer\")\n",
    "model.add(Conv2D(16,kernel_size=2, input_shape = input_shape, activation = 'relu', name = \"conv2d_layer1\"))\n",
    "model.add(Conv2D(32,kernel_size=3, activation = 'relu', name = \"conv2d_layer2\"))\n",
    "model.add(Flatten(name = \"flatten_layer\"))\n",
    "model.add(Dense(256, activation = 'relu', name = \"dense_layer1\"))\n",
    "model.add(Dense(n_actions, activation = 'linear', name = \"dense_layer2\"))\n",
    "model.compile(optimizer = RMSprop(), loss='MSE')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccacdd19-0362-485b-a58d-456aa509fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This is the model I used which is way simpler than the original one (as you can see by the number of parameters).'''\n",
    "model = Sequential(name=\"sequential_layer\")\n",
    "model.add(Dense(surgery_env.surgery_mat.size, input_shape=(surgery_env.surgery_mat.size,)))\n",
    "model.add(PReLU())\n",
    "model.add(Dense(surgery_env.surgery_mat.size))\n",
    "model.add(PReLU())\n",
    "model.add(Dense(n_actions))\n",
    "model.compile(optimizer = 'adam', loss='MSE')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e802a89a-00c0-44cf-b0c4-1924293bda43",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3dd7dd-9e17-48ad-a121-ce46f8285a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 1500 #number of episodes\n",
    "minibatch_size = 32 #size of the batch used in the Replay function\n",
    "mem_max_size = 100000 #maximum number of episodes can be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb937ddf-cc5b-4ce0-bed1-0f5e6b0ec755",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "epsilon = 1.0\n",
    "r_sums = [] #list to contain the sums of the rewards for each episode\n",
    "replay_memory = [] #list to contain the step and retrain the model\n",
    "\n",
    "for n in range(n_episodes):\n",
    "\n",
    "    surgery_env.reset_env() \n",
    "    done = False\n",
    "    r_sum = 0\n",
    "    \n",
    "    while not done:\n",
    "        s = surgery_env.surgery_mat.reshape(1,-1).copy()\n",
    "        \n",
    "        if np.random.rand() < epsilon: #to enhance exploration\n",
    "            a = rnd.choice(surgery_env.action_space) #choose a random action\n",
    "        else: \n",
    "            qvals_s = model.predict(s)\n",
    "            a = np.argmax(qvals_s)\n",
    "        \n",
    "        s_prime , r, done, _ = surgery_env.step_env(a)\n",
    "        r_sum += r\n",
    "        \n",
    "        if len(replay_memory) > mem_max_size: #if the buffer is full, pop the least recent episode\n",
    "            replay_memory.pop(0)\n",
    "            \n",
    "        replay_memory.append({\"s\":s,\"a\":a,\"r\":r,\"s_prime\":s_prime.reshape(1,-1),\"done\":done}) #store the step\n",
    "        model= replay(model, replay_memory, minibatch_size = minibatch_size, env_size = surgery_env.surgery_mat.size) #train the model on past steps\n",
    "        \n",
    "    if epsilon > 0.001: #decrease the epsilon value\n",
    "        epsilon -= 0.005 \n",
    "    \n",
    "    r_sums.append(r_sum)\n",
    "    plt.plot(r_sums, color='red') #plot of the rewards\n",
    "    \n",
    "    if n >= 3: #after 3 episodes it's possible to plot also the trend line\n",
    "        \n",
    "        x = np.linspace(0,len(r_sums), len(r_sums), dtype= np.int32)\n",
    "        z = np.polyfit(x, r_sums, 3)\n",
    "        p = np.poly1d(z)\n",
    "        plt.plot(x, p(x), linewidth = 2.5, color='blue')\n",
    "    \n",
    "    \n",
    "    plt.title(f'Episode {n+1},  \\u03B5= {round(epsilon,3)},  Avg reward={round(mean(r_sums),3)}')\n",
    "    \n",
    "    if (n!=n_episodes - 1): #until the training is not finished\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.pause(1.0)\n",
    "        plt.cla()\n",
    "        \n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "model.save('./knifeAgent_'+str(n_episodes)+'Episodes.h5') #saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbb61d6-b675-4427-8cc7-cf98023a4dc6",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b35c5-e36f-4f16-8866-8c0e06909ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = load_model('./knifeAgent_'+str(n_episodes)+'Episodes.h5') #loading the trained model (to save time)\n",
    "\n",
    "test_env = SurgeryEnv()\n",
    "test_env.reset_env()\n",
    "\n",
    "finished = False\n",
    "rsum = 0\n",
    "frames = [test_env.surgery_mat.copy()] #this is for creating the animation\n",
    "\n",
    "while not finished:\n",
    "    \n",
    "    s=test_env.surgery_mat.reshape(1,-1).copy()\n",
    "    qvals = trained_model.predict(s)\n",
    "    action = np.argmax(qvals)\n",
    "    _ , reward, finished, info = test_env.step_env(action)\n",
    "    print('Path:', info['path'])\n",
    "    print('Actions', info['taken_actions'])\n",
    "    print()\n",
    "    rsum += reward\n",
    "    \n",
    "    frames.append(test_env.surgery_mat.copy()) #storing the frame \n",
    "    \n",
    "print('Total reward:', rsum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1069b-0860-4cac-89f3-f46179866047",
   "metadata": {},
   "source": [
    "## Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563c9c2-f4e2-44b2-95b9-705adc68d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "\n",
    "fps= len(frames)\n",
    "nSeconds = len(frames)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "\n",
    "a = frames[0]\n",
    "im = plt.imshow(a, interpolation='none', aspect='auto', vmin=0, vmax=255)\n",
    "anim = FuncAnimation(\n",
    "                               fig, \n",
    "                               animate_func, \n",
    "                               frames = len(frames),\n",
    "                               interval = 10000 / fps, # ms\n",
    "                               )\n",
    "\n",
    "anim.save('./knifeAgent_'+str(n_episodes)+'Episodes.gif', writer='imagemagick', fps=int(fps/2)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
